{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP8Fj3UUe5amP8NuH0dpJiZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Question 1: EDA ‚Äì Sentiment Analysis from Drug Reviews (Easy)\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n"],"metadata":{"id":"y655D-NEANZz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('drugLibTrain_raw.tsv', sep='\\t')"],"metadata":{"id":"mBCTcTLiAWow"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Dataset Info:\")\n","print(df.info())\n","print(\"\\nDataset Shape:\", df.shape)\n","\n","print(\"\\nFirst 5 Rows:\")\n","print(df.head())\n"],"metadata":{"id":"VQv_6nC2Bqnz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\n Missing Values:\")\n","print(df.isnull().sum())"],"metadata":{"id":"2lrSdqiHCG4o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","if 'condition' in df.columns:\n","    print(\"\\n Condition distribution:\")\n","    print(df['condition'].value_counts())\n","\n","if 'rating' in df.columns:\n","    print(\"\\n Rating distribution:\")\n","    print(df['rating'].value_counts())\n","\n","if 'sentiment' in df.columns:\n","    print(\"\\n Sentiment distribution:\")\n","    print(df['sentiment'].value_counts())"],"metadata":{"id":"xzr2JbgQCK2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if 'condition' in df.columns:\n","    print(\"\\n Condition distribution (%):\")\n","    print(df['condition'].value_counts(normalize=True) * 100)\n","\n","if 'rating' in df.columns:\n","    print(\"\\n Rating distribution (%):\")\n","    print(df['rating'].value_counts(normalize=True) * 100)\n","\n","if 'sentiment' in df.columns:\n","    print(\"\\n Sentiment distribution (%):\")\n","    print(df['sentiment'].value_counts(normalize=True) * 100)"],"metadata":{"id":"VNkFENccCNVO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if 'condition' in df.columns:\n","    plt.figure(figsize=(12, 6))\n","    df['condition'].value_counts().head(10).plot(kind='barh', color='skyblue')\n","    plt.title('Top 10 Most Common Conditions')\n","    plt.xlabel('Frequency')\n","    plt.ylabel('Condition')\n","    plt.gca().invert_yaxis()\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"bTpdiRRACREY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if 'rating' in df.columns:\n","    plt.figure(figsize=(8, 4))\n","    sns.countplot(x='rating', data=df, palette='viridis')\n","    plt.title('Rating Distribution')\n","    plt.xlabel('Rating')\n","    plt.ylabel('Count')\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"Tx6ZqnVGCW2Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if 'sentiment' in df.columns:\n","    plt.figure(figsize=(6, 4))\n","    sns.countplot(x='sentiment', data=df, palette='Set2')\n","    plt.title('Sentiment Distribution')\n","    plt.xlabel('Sentiment')\n","    plt.ylabel('Count')\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"sptJUlvuCZQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","df = pd.read_csv('drugLibTrain_raw.tsv', sep='\\t')\n","\n","top_conditions = df['condition'].value_counts().head(10)\n","\n","# Plot\n","plt.figure(figsize=(12, 6))\n","top_conditions.plot(kind='barh', color='cornflowerblue')\n","plt.title('Top 10 Most Common Drug Conditions')\n","plt.xlabel('Frequency')\n","plt.ylabel('Condition')\n","plt.gca().invert_yaxis()\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"WgbYJjxlCyMn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df[df['condition'].notnull()]"],"metadata":{"id":"HRXMAcXUC8ga"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Drop rows with missing drugName or rating\n","df = df.dropna(subset=['urlDrugName', 'rating'])\n","\n","# Calculate average rating per drug\n","avg_rating = df.groupby('urlDrugName')['rating'].mean().sort_values(ascending=False)\n","\n","# Optionally: Filter to only drugs with enough reviews (e.g., at least 10)\n","drug_counts = df['urlDrugName'].value_counts()\n","popular_drugs = drug_counts[drug_counts >= 10].index\n","avg_rating_filtered = avg_rating[avg_rating.index.isin(popular_drugs)]\n","\n","# Select top 20 drugs by average rating\n","top_avg_rated = avg_rating_filtered.head(20)\n","\n","# Plot\n","plt.figure(figsize=(12, 6))\n","top_avg_rated.sort_values().plot(kind='barh', color='mediumseagreen')\n","plt.title('Top 20 Drugs by Average Rating (‚â•10 Reviews)')\n","plt.xlabel('Average Rating')\n","plt.ylabel('Drug Name')\n","plt.xlim(0, 10)  # Ratings usually from 1 to 10\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"zLG-oOj6DTsH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df.columns.tolist())"],"metadata":{"id":"5SQfED6wE0D6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from wordcloud import WordCloud, STOPWORDS\n","import re\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","# Load data\n","df = pd.read_csv('drugLibTrain_raw.tsv', sep='\\t')\n","\n","# --- Step 1: Clean review text ---\n","def clean_text(text):\n","    if pd.isnull(text):\n","        return ''\n","    text = text.lower()  # lowercase\n","    text = re.sub(r'<.*?>', '', text)  # remove HTML tags\n","    text = re.sub(r'[^a-z\\s]', '', text)  # keep only letters\n","    text = re.sub(r'\\s+', ' ', text).strip()  # remove extra whitespace\n","    return text\n","\n","# Apply to the review/comments column\n","text_col = 'benefitsReview' if 'sideEffectsReview' in df.columns else 'commentsReview'\n","df[text_col] = df[text_col].apply(clean_text)\n","\n","# --- Step 2: Assign sentiment ---\n","df = df[df['rating'].notnull()]  # drop NaN ratings\n","df['sentiment'] = df['rating'].apply(lambda x: 'positive' if x >= 7 else ('negative' if x <= 3 else 'neutral'))\n","\n","# --- Step 3: Separate positive and negative texts ---\n","positive_text = ' '.join(df[df['sentiment'] == 'positive'][text_col])\n","negative_text = ' '.join(df[df['sentiment'] == 'negative'][text_col])\n","\n","# --- Step 4: Generate word clouds ---\n","stopwords = set(STOPWORDS)\n","\n","# Positive word cloud\n","positive_wc = WordCloud(width=800, height=400, background_color='white', stopwords=stopwords, colormap='Greens').generate(positive_text)\n","plt.figure(figsize=(10, 5))\n","plt.imshow(positive_wc, interpolation='bilinear')\n","plt.axis('off')\n","plt.title('üåü Word Cloud for Positive Reviews')\n","plt.show()\n","\n","# Negative word cloud\n","negative_wc = WordCloud(width=800, height=400, background_color='white', stopwords=stopwords, colormap='Reds').generate(negative_text)\n","plt.figure(figsize=(10, 5))\n","plt.imshow(negative_wc, interpolation='bilinear')\n","plt.axis('off')\n","plt.title('üí¢ Word Cloud for Negative Reviews')\n","plt.show()\n"],"metadata":{"id":"DqGmJ_OZLXcY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df.columns.tolist())"],"metadata":{"id":"wBANNXw0ME3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #Classification ‚Äì Review Sentiment Prediction (Medium)\n","#1.\tConvert ratings to binary sentiment labels (e.g., rating ‚â• 7 ‚Üí positive, else negative).\n","\n","\n","# Drop rows with missing ratings or review text\n","df = df.dropna(subset=['rating', 'commentsReview'])  # replace 'comments' if your review column is named differently\n","\n","# Convert ratings to binary sentiment\n","df['sentiment'] = df['rating'].apply(lambda x: 'positive' if x >= 7 else 'negative')\n","\n","# Preview the results\n","print(df[['rating', 'sentiment']].head())\n","print(\"\\nSentiment class distribution:\")\n","print(df['sentiment'].value_counts())\n"],"metadata":{"id":"djzAgWSxP-VG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df.columns.tolist())"],"metadata":{"id":"ON2OIdI_O6YR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","# Download required NLTK resources\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('punkt_tab')"],"metadata":{"id":"3UApmR_XQWDn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","# Load dataset\n","#df = pd.read_csv('drugLibTrain_raw.tsv', sep='\\t')\n","\n","# Drop missing values in key columns\n","df = df.dropna(subset=['commentsReview', 'rating'])\n","\n","# Create sentiment column (if not already present)\n","df['sentiment'] = df['rating'].apply(lambda x: 'positive' if x >= 7 else 'negative')\n","\n","# Initialize stopwords and lemmatizer\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()\n","\n","\n","def preprocess(text):\n","    if not isinstance(text, str):  # avoid non-string input\n","        return \"\"\n","    text = text.lower()\n","    text = re.sub(r'<.*?>', '', text)           # remove HTML tags\n","    text = re.sub(r'[^a-z\\s]', '', text)        # remove punctuation & digits\n","    try:\n","        tokens = word_tokenize(text)            # tokenize\n","    except Exception as e:\n","        print(\"Tokenization error:\", e)\n","        return \"\"\n","    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words and len(w) > 2]\n","    return ' '.join(tokens)\n","\n","\n","# Apply preprocessing\n","# ‚úÖ This line applies preprocessing to the comments\n","df['cleaned_text'] = df['commentsReview'].apply(preprocess)\n","\n","# Preview result\n","df[['commentsReview', 'effectiveness', 'sentiment']].head()\n","\n"],"metadata":{"id":"meKF9vOYQexg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Input: cleaned text\n","texts = df['effectiveness']\n","\n","# Vectorizer\n","vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n","X = vectorizer.fit_transform(texts)\n","\n","# Output labels\n","y = df['sentiment']\n","\n","print(\"TF-IDF feature matrix shape:\", X.shape)\n"],"metadata":{"id":"Q-ME2z6mREMB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#4.\tTrain and evaluate Logistic Regression and Random Forest models\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"],"metadata":{"id":"8L16L467UTCB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming you already have:\n","# - X: TF-IDF features (from TfidfVectorizer)\n","# - y: sentiment labels (positive/negative)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"],"metadata":{"id":"WZECRwioUeyw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize and train\n","logreg = LogisticRegression(max_iter=1000)\n","logreg.fit(X_train, y_train)\n","\n","# Predict\n","y_pred_logreg = logreg.predict(X_test)\n","\n","# Evaluate\n","print(\"üîπ Logistic Regression Results:\")\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n","print(classification_report(y_test, y_pred_logreg))\n"],"metadata":{"id":"gO910lfEUXU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #Train Logistic Regression\n","# Initialize and train\n","logreg = LogisticRegression(max_iter=1000)\n","logreg.fit(X_train, y_train)\n","\n","# Predict\n","y_pred_logreg = logreg.predict(X_test)\n","\n","# Evaluate\n","print(\"üîπ Logistic Regression Results:\")\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n","print(classification_report(y_test, y_pred_logreg))\n"],"metadata":{"id":"bvexLzG-UhUg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["      #Train Random Forest\n","# Initialize and train\n","rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf.fit(X_train, y_train)\n","\n","# Predict\n","y_pred_rf = rf.predict(X_test)\n","\n","# Evaluate\n","print(\"üîπ Random Forest Results:\")\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n","print(classification_report(y_test, y_pred_rf))\n"],"metadata":{"id":"NCNBgkbeUjqJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["      # Confusion Matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","# Confusion Matrix for Logistic Regression\n","ConfusionMatrixDisplay.from_predictions(y_test, y_pred_logreg)\n","plt.title(\"Logistic Regression Confusion Matrix\")\n","plt.show()\n","\n","# Confusion Matrix for Random Forest\n","ConfusionMatrixDisplay.from_predictions(y_test, y_pred_logreg)\n","plt.title(\"Random Forest Confusion Matrix\")\n","plt.show()\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Train Random Forest\n","rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf.fit(X_train, y_train)\n","\n","# Predict on test set\n","y_pred_rf = rf.predict(X_test)\n"],"metadata":{"id":"ABE6EmPcUn8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","# Confusion Matrix for Logistic Regression\n","ConfusionMatrixDisplay.from_predictions(y_test, y_pred_logreg)\n","plt.title(\"Logistic Regression Confusion Matrix\")\n","plt.show()\n","\n","# Confusion Matrix for Random Forest\n","ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rf)\n","plt.title(\"Random Forest Confusion Matrix\")\n","plt.show()\n"],"metadata":{"id":"GzT7gAI4VG6p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#5.\tCompare precision, recall, and F1-score.\n","\n","from sklearn.metrics import classification_report\n","\n","# Print evaluation for Logistic Regression\n","print(\"üîπ Logistic Regression Report:\")\n","print(classification_report(y_test, y_pred_logreg))\n","\n","# Print evaluation for Random Forest\n","print(\"üîπ Random Forest Report:\")\n","print(classification_report(y_test, y_pred_rf))\n"],"metadata":{"id":"KQTmwn_MVlc7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","import pandas as pd\n","\n","# Get reports as dicts\n","log_report = classification_report(y_test, y_pred_logreg, output_dict=True)\n","rf_report = classification_report(y_test, y_pred_rf, output_dict=True)\n","\n","# Create comparison DataFrame\n","comparison_df = pd.DataFrame({\n","    'Logistic Regression': pd.Series(log_report['weighted avg']),\n","    'Random Forest': pd.Series(rf_report['weighted avg'])\n","})\n","\n","print(\"üîç Precision/Recall/F1 Comparison (Weighted Average):\")\n","print(comparison_df[['Logistic Regression', 'Random Forest']])\n"],"metadata":{"id":"MVBSgEESVowr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#6.\tPerform hyperparameter tuning on the better model.\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n"],"metadata":{"id":"30tg9KNCV5ld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["param_grid = {\n","    'n_estimators': [100, 200],\n","    'max_depth': [10, 20, None],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2],\n","    'bootstrap': [True, False]\n","}\n"],"metadata":{"id":"NDQBwqiSV-o1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use original X_train and y_train from your train/test split\n","rf = RandomForestClassifier(random_state=42)\n","\n","grid_search = GridSearchCV(estimator=rf,\n","                           param_grid=param_grid,\n","                           cv=3,\n","                           n_jobs=-1,\n","                           verbose=2,\n","                           scoring='f1_weighted')\n","\n","grid_search.fit(X_train, y_train)\n"],"metadata":{"id":"e7I9zv6yWFgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Best Parameters:\", grid_search.best_params_)\n","\n","# Predict with best estimator\n","best_rf = grid_search.best_estimator_\n","y_pred_best = best_rf.predict(X_test)\n","\n","# Evaluate\n","from sklearn.metrics import classification_report\n","print(\"Tuned Random Forest Results:\")\n","print(classification_report(y_test, y_pred_best))\n"],"metadata":{"id":"dWpfgDrtWHAI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#7.\tSave final model and vectorizer for deployment.\n","import joblib\n","\n","# Save best model (e.g., Random Forest)\n","joblib.dump(best_rf, 'sentiment_model.pkl')\n","\n","# Save TF-IDF vectorizer\n","joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n","\n","print(\"‚úÖ Model and vectorizer saved successfully!\")\n"],"metadata":{"id":"9b2V2mzKWQpv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n","\n","# Load model and vectorizer\n","model = joblib.load('sentiment_model.pkl')\n","vectorizer = joblib.load('tfidf_vectorizer.pkl')\n","\n","# Predict new review\n","new_review = [\"I feel great after taking this medicine.\"]\n","cleaned = preprocess(new_review[0])  # use your preprocessing function\n","features = vectorizer.transform([cleaned])\n","prediction = model.predict(features)\n","\n","print(\"Prediction:\", prediction[0])\n"],"metadata":{"id":"VbWjIq48WaiN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Question 3: Transformer-Based Sentiment Analysis Web App (Hard)\n","#1.\tFine-tune a transformer (e.g., distilbert-base-uncased) for binary sentiment\n","!pip install transformers datasets scikit-learn torch"],"metadata":{"id":"D44l_NodWdgn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"drugLibTrain_raw.tsv\", sep=\"\\t\")\n","# Convert rating to binary sentiment\n","df['label'] = df['rating'].apply(lambda x: 1 if x >= 7 else 0)\n","\n","# Drop missing rows\n","df = df.dropna(subset=['commentsReview', 'label'])\n","\n","# Rename for clarity\n","df = df.rename(columns={'commentsReview': 'text'})\n"],"metadata":{"id":"7lXfC4-GXiGo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset\n","\n","dataset = Dataset.from_pandas(df[['text', 'label']])\n"],"metadata":{"id":"lmiDDg0LXmcW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DistilBertTokenizerFast\n","\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n","\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n"],"metadata":{"id":"svXF4-QSXqDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n"],"metadata":{"id":"8qSHpYssXrmq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DistilBertForSequenceClassification\n","\n","model = DistilBertForSequenceClassification.from_pretrained(\n","    \"distilbert-base-uncased\", num_labels=2\n",")\n"],"metadata":{"id":"-qIgf2HQXtVD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install"],"metadata":{"id":"EtXVxP1QZKaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import transformers\n","print(transformers.__version__)"],"metadata":{"id":"WM-HLfpjZdRc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    do_train=True,\n","    do_eval=True,\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    logging_dir=\"./logs\",\n",")"],"metadata":{"id":"cZP4F9RIovCj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, f1_score\n","import numpy as np\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","\n","    # Binary classification handling:\n","    if logits.shape[1] == 1:\n","        # Single sigmoid output (num_labels=1)\n","        preds = (logits > 0).astype(int)\n","    else:\n","        # Two-class softmax output (num_labels=2)\n","        preds = np.argmax(logits, axis=1)\n","\n","    return {\n","        \"accuracy\": accuracy_score(labels, preds),\n","        \"f1\": f1_score(labels, preds)\n","    }\n","\n"],"metadata":{"id":"J13HAE6NrIzd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n"],"metadata":{"id":"FMYg65XdrTZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n"],"metadata":{"id":"W59VXuKEo1_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_pretrained(\"./distilbert-sentiment\")\n","tokenizer.save_pretrained(\"./distilbert-sentiment\")\n"],"metadata":{"id":"BBx2eE64X3Cu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","!pip install transformers datasets\n"],"metadata":{"id":"42xwlhkuX7B7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#2.\tTokenize and encode the text.\n","from transformers import DistilBertTokenizerFast\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n"],"metadata":{"id":"4VQQ4vKQYGFE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenization Function\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n"],"metadata":{"id":"RV1WJ85bYJam"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset = dataset.map(tokenize_function, batched=True)\n"],"metadata":{"id":"RhMjdHDzYQxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"This drug worked really well for my condition.\"\n","\n","# Encode a single text\n","encoded_input = tokenizer(text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n","\n","print(encoded_input)\n"],"metadata":{"id":"6p19jrKLYSoA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##4.\tEvaluate performance using accuracy and F1-score.\n","from sklearn.metrics import accuracy_score, f1_score\n","import numpy as np\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    # Convert logits to predictions (for binary classification, threshold at 0.5)\n","    preds = (logits > 0).astype(int) if logits.shape[1] == 1 else np.argmax(logits, axis=1)\n","\n","    return {\n","        'accuracy': accuracy_score(labels, preds),\n","        'f1': f1_score(labels, preds)\n","    }\n"],"metadata":{"id":"lzNgxSh1aKw0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#5.\tBuild a Streamlit app\n","#Input: User enters a drug review.\n","#Output: Predicted sentiment (positive/negative) + confidence score.\n","# Display attention map or top words influencing prediction.\n","!pip install streamlit transformers torch\n","\n","\n"],"metadata":{"id":"GoTDJ0pYa4KP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import streamlit as st\n","import torch\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n","\n","@st.cache_resource\n","def load_model():\n","    model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-sentiment\")\n","    tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-sentiment\")\n","    return model, tokenizer\n"],"metadata":{"id":"J4e6u0dqbKdF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import streamlit as st\n","import torch\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n","import torch.nn.functional as F\n","\n","# Load model and tokenizer once\n","@st.cache_resource\n","def load_model():\n","    model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-sentiment\")\n","    tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-sentiment\")\n","    return model, tokenizer\n","\n","model, tokenizer = load_model()\n","model.eval()\n","\n","# App UI\n","st.title(\"Drug Review Sentiment Analyzer\")\n","st.write(\"Enter a drug review to analyze sentiment (positive or negative).\")\n","\n","text = st.text_area(\"Your drug review:\", height=150)\n","\n","if text:\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","\n","        if logits.shape[1] == 1:\n","            probs = torch.sigmoid(logits)\n","            pred = int(probs > 0.5)\n","            confidence = probs.item()\n","        else:\n","            probs = F.softmax(logits, dim=1)\n","            pred = torch.argmax(probs, dim=1).item()\n","            confidence = probs[0][pred].item()\n","\n","    label = \"Positive\" if pred == 1 else \"Negative\"\n","    st.markdown(f\"### Prediction: {label}\")\n","    st.markdown(f\"**Confidence:** `{confidence:.2f}`\")\n","\n","    # Approximate token influence using attention-like display\n","    st.subheader(\"üîç Top Influential Words (Token Importance Approximation)\")\n","    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n","    token_scores = probs[0][pred].item()  # crude single-score heat\n","\n","    # Simple heat-based highlight\n","    for token in tokens:\n","        clean_token = token.replace(\"##\", \"\")\n","        opacity = confidence  # just a flat display based on confidence\n","        st.markdown(\n","            f\"<span style='background-color:rgba(30,144,255,{opacity}); color:white; padding:3px; margin:2px; border-radius:5px'>{clean_token}</span> \",\n","            unsafe_allow_html=True\n","        )\n"],"metadata":{"id":"pX1LX6pYbWjB"},"execution_count":null,"outputs":[]}]}